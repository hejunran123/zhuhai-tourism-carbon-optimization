"""
ç æµ·å¸‚æ–‡æ—…è®¾æ–½ç¢³æ’æ”¾æ¨¡å‹ - æ™ºèƒ½æ•°æ®ç”Ÿæˆç³»ç»Ÿ
é˜¶æ®µä¸€ï¼šæ•°æ®è´¨é‡ä¼˜åŒ–
ä½œè€…ï¼šä¼˜åŒ–å›¢é˜Ÿ
æ—¥æœŸï¼š2025å¹´1æœˆ
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.spatial.distance import pdist, squareform
from scipy import stats
from sklearn.preprocessing import StandardScaler
import warnings
warnings.filterwarnings('ignore')

class SpatialDataGenerator:
    """ç©ºé—´ç›¸å…³æ•°æ®ç”Ÿæˆå™¨"""
    
    def __init__(self, study_area_bounds, grid_size=1000):
        """
        åˆå§‹åŒ–ç©ºé—´æ•°æ®ç”Ÿæˆå™¨
        
        Args:
            study_area_bounds: (xmin, ymin, xmax, ymax) ç ”ç©¶åŒºåŸŸè¾¹ç•Œ
            grid_size: ç½‘æ ¼å¤§å°ï¼ˆç±³ï¼‰
        """
        self.bounds = study_area_bounds
        self.grid_size = grid_size
        self.coords = None
        self.carbon_values = None
        
        print(f"âœ… ç©ºé—´æ•°æ®ç”Ÿæˆå™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"   ç ”ç©¶åŒºåŸŸ: {study_area_bounds}")
        print(f"   ç½‘æ ¼å¤§å°: {grid_size}m")
    
    def generate_spatial_correlated_data(self, correlation_range=3000, base_emission=100, variance=50):
        """
        ç”Ÿæˆç©ºé—´ç›¸å…³çš„ç¢³æ’æ”¾æ•°æ®
        
        Args:
            correlation_range: ç©ºé—´ç›¸å…³è·ç¦»ï¼ˆç±³ï¼‰
            base_emission: åŸºç¡€æ’æ”¾é‡
            variance: æ’æ”¾é‡æ–¹å·®
        """
        print(f"\nğŸ”§ ç”Ÿæˆç©ºé—´ç›¸å…³ç¢³æ’æ”¾æ•°æ®...")
        
        # åˆ›å»ºç½‘æ ¼ç‚¹ (è½¬æ¢åº¦æ•°åˆ°ç±³çš„è¿‘ä¼¼)
        # 1åº¦ç»åº¦çº¦ç­‰äº111kmï¼Œ1åº¦çº¬åº¦çº¦ç­‰äº111km
        grid_size_deg = self.grid_size / 111000  # è½¬æ¢ä¸ºåº¦æ•°
        x_coords = np.arange(self.bounds[0], self.bounds[2], grid_size_deg)
        y_coords = np.arange(self.bounds[1], self.bounds[3], grid_size_deg)
        xx, yy = np.meshgrid(x_coords, y_coords)
        
        # å±•å¹³åæ ‡
        self.coords = np.column_stack([xx.ravel(), yy.ravel()])
        n_points = len(self.coords)
        
        print(f"   ç½‘æ ¼ç‚¹æ•°é‡: {n_points:,}")
        
        # è®¡ç®—è·ç¦»çŸ©é˜µ (è½¬æ¢ä¸ºç±³)
        print(f"   è®¡ç®—è·ç¦»çŸ©é˜µ...")
        coords_meters = self.coords * 111000  # è½¬æ¢ä¸ºç±³
        distances = squareform(pdist(coords_meters))
        
        # æ„å»ºåæ–¹å·®çŸ©é˜µï¼ˆæŒ‡æ•°è¡°å‡æ ¸å‡½æ•°ï¼‰
        print(f"   æ„å»ºåæ–¹å·®çŸ©é˜µ...")
        covariance_matrix = variance * np.exp(-distances / correlation_range)
        
        # æ·»åŠ å¯¹è§’çº¿å™ªå£°ä»¥ç¡®ä¿æ­£å®šæ€§
        covariance_matrix += np.eye(n_points) * 0.1
        
        # ç”Ÿæˆå¤šå…ƒæ­£æ€åˆ†å¸ƒæ•°æ®
        print(f"   ç”Ÿæˆå¤šå…ƒæ­£æ€åˆ†å¸ƒæ•°æ®...")
        
        # å¯¹äºå¤§çŸ©é˜µï¼Œä½¿ç”¨ç®€åŒ–æ–¹æ³•é¿å…å†…å­˜é—®é¢˜
        if n_points > 1000:
            print(f"   ä½¿ç”¨ç®€åŒ–æ–¹æ³•å¤„ç†å¤§æ•°æ®é›†...")
            # ä½¿ç”¨è·ç¦»è¡°å‡ç›´æ¥ç”Ÿæˆç›¸å…³æ•°æ®
            mean = np.full(n_points, base_emission)
            carbon_raw = np.zeros(n_points)
            
            # éšæœºé€‰æ‹©ä¸€äº›ç§å­ç‚¹
            n_seeds = min(50, n_points // 10)
            seed_indices = np.random.choice(n_points, n_seeds, replace=False)
            seed_values = np.random.normal(base_emission, variance, n_seeds)
            
            # åŸºäºè·ç¦»æ’å€¼
            for i in range(n_points):
                weights = np.exp(-distances[i, seed_indices] / correlation_range)
                weights /= weights.sum()
                carbon_raw[i] = np.sum(weights * seed_values) + np.random.normal(0, variance * 0.1)
        else:
            try:
                mean = np.full(n_points, base_emission)
                carbon_raw = np.random.multivariate_normal(mean, covariance_matrix)
            except np.linalg.LinAlgError:
                # å¦‚æœåæ–¹å·®çŸ©é˜µå¥‡å¼‚ï¼Œä½¿ç”¨Choleskyåˆ†è§£çš„æ›¿ä»£æ–¹æ³•
                print(f"   ä½¿ç”¨æ›¿ä»£æ–¹æ³•ç”Ÿæˆæ•°æ®...")
                eigenvals, eigenvecs = np.linalg.eigh(covariance_matrix)
                eigenvals = np.maximum(eigenvals, 0.1)  # ç¡®ä¿æ­£ç‰¹å¾å€¼
                sqrt_cov = eigenvecs @ np.diag(np.sqrt(eigenvals)) @ eigenvecs.T
                carbon_raw = mean + sqrt_cov @ np.random.normal(0, 1, n_points)
        
        # ç¡®ä¿éè´Ÿå€¼å¹¶è°ƒæ•´åˆ°åˆç†èŒƒå›´
        self.carbon_values = np.maximum(carbon_raw, 10)  # æœ€å°10å¨CO2/å¹´
        
        # è®¡ç®—ç©ºé—´è‡ªç›¸å…³æ€§
        spatial_correlation = self.calculate_spatial_autocorrelation()
        
        print(f"âœ… ç©ºé—´ç›¸å…³æ•°æ®ç”Ÿæˆå®Œæˆ")
        print(f"   ç©ºé—´è‡ªç›¸å…³ç³»æ•°: {spatial_correlation:.3f}")
        print(f"   æ’æ”¾é‡èŒƒå›´: {self.carbon_values.min():.1f} - {self.carbon_values.max():.1f} å¨CO2/å¹´")
        print(f"   å¹³å‡æ’æ”¾é‡: {self.carbon_values.mean():.1f} å¨CO2/å¹´")
        
        return self.coords, self.carbon_values
    
    def calculate_spatial_autocorrelation(self, max_distance=5000):
        """è®¡ç®—ç©ºé—´è‡ªç›¸å…³ç³»æ•°ï¼ˆMoran's Iï¼‰"""
        if self.coords is None or self.carbon_values is None:
            return 0
        
        # è®¡ç®—è·ç¦»æƒé‡çŸ©é˜µ (è½¬æ¢ä¸ºç±³)
        coords_meters = self.coords * 111000  # è½¬æ¢ä¸ºç±³
        distances = squareform(pdist(coords_meters))
        weights = np.where(distances <= max_distance, 1/np.maximum(distances, 1), 0)
        np.fill_diagonal(weights, 0)
        
        # æ ‡å‡†åŒ–æƒé‡
        row_sums = weights.sum(axis=1)
        weights = weights / np.maximum(row_sums[:, np.newaxis], 1)
        
        # è®¡ç®—Moran's I
        n = len(self.carbon_values)
        mean_val = np.mean(self.carbon_values)
        deviations = self.carbon_values - mean_val
        
        numerator = np.sum(weights * np.outer(deviations, deviations))
        denominator = np.sum(deviations**2)
        
        morans_i = (n / np.sum(weights)) * (numerator / denominator) if denominator > 0 else 0
        
        return morans_i
    
    def add_urban_centers(self, centers, intensities):
        """æ·»åŠ åŸå¸‚ä¸­å¿ƒçš„é«˜æ’æ”¾åŒºåŸŸ"""
        if self.coords is None or self.carbon_values is None:
            print("âš ï¸ è¯·å…ˆç”ŸæˆåŸºç¡€ç©ºé—´æ•°æ®")
            return
        
        print(f"\nğŸ™ï¸ æ·»åŠ åŸå¸‚ä¸­å¿ƒé«˜æ’æ”¾åŒºåŸŸ...")
        
        for i, (center, intensity) in enumerate(zip(centers, intensities)):
            # è®¡ç®—åˆ°åŸå¸‚ä¸­å¿ƒçš„è·ç¦» (è½¬æ¢ä¸ºç±³)
            distances_to_center = np.sqrt(
                ((self.coords[:, 0] - center[0]) * 111000)**2 + 
                ((self.coords[:, 1] - center[1]) * 111000)**2
            )
            
            # è·ç¦»è¡°å‡å‡½æ•°
            decay_factor = np.exp(-distances_to_center / 2000)  # 2kmè¡°å‡è·ç¦»
            
            # å¢åŠ æ’æ”¾é‡
            self.carbon_values += intensity * decay_factor
            
            print(f"   åŸå¸‚ä¸­å¿ƒ {i+1}: ({center[0]:.0f}, {center[1]:.0f}), å¼ºåº¦: {intensity}")
        
        print(f"âœ… åŸå¸‚ä¸­å¿ƒæ•ˆåº”æ·»åŠ å®Œæˆ")
        print(f"   æ›´æ–°åæ’æ”¾é‡èŒƒå›´: {self.carbon_values.min():.1f} - {self.carbon_values.max():.1f} å¨CO2/å¹´")
    
    def visualize_spatial_data(self, save_path=None):
        """å¯è§†åŒ–ç©ºé—´æ•°æ®"""
        if self.coords is None or self.carbon_values is None:
            print("âš ï¸ æ²¡æœ‰æ•°æ®å¯è§†åŒ–")
            return None
        
        fig, axes = plt.subplots(1, 2, figsize=(15, 6))
        
        # ç©ºé—´åˆ†å¸ƒå›¾
        scatter = axes[0].scatter(
            self.coords[:, 0], self.coords[:, 1], 
            c=self.carbon_values, cmap='YlOrRd', 
            s=20, alpha=0.7
        )
        axes[0].set_title('ç¢³æ’æ”¾ç©ºé—´åˆ†å¸ƒ')
        axes[0].set_xlabel('Xåæ ‡ (m)')
        axes[0].set_ylabel('Yåæ ‡ (m)')
        plt.colorbar(scatter, ax=axes[0], label='ç¢³æ’æ”¾é‡ (å¨CO2/å¹´)')
        
        # æ’æ”¾é‡åˆ†å¸ƒç›´æ–¹å›¾
        axes[1].hist(self.carbon_values, bins=50, alpha=0.7, color='skyblue', edgecolor='black')
        axes[1].set_title('ç¢³æ’æ”¾é‡åˆ†å¸ƒ')
        axes[1].set_xlabel('ç¢³æ’æ”¾é‡ (å¨CO2/å¹´)')
        axes[1].set_ylabel('é¢‘æ•°')
        axes[1].axvline(self.carbon_values.mean(), color='red', linestyle='--', 
                       label=f'å‡å€¼: {self.carbon_values.mean():.1f}')
        axes[1].legend()
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"âœ… å›¾è¡¨å·²ä¿å­˜: {save_path}")
        
        return fig


class POITypeModeling:
    """POIç±»å‹ç‰¹å¾å»ºæ¨¡"""
    
    def __init__(self):
        """åˆå§‹åŒ–POIç±»å‹å»ºæ¨¡å™¨"""
        # åŸºäºè¡Œä¸šç ”ç©¶çš„æ’æ”¾åˆ†å¸ƒå‚æ•°
        self.emission_distributions = {
            'æ™¯ç‚¹': {
                'dist': 'lognormal', 
                'params': {'mu': 8.0, 'sigma': 0.8},
                'description': 'æ™¯ç‚¹æ’æ”¾å‘ˆå¯¹æ•°æ­£æ€åˆ†å¸ƒï¼Œå¤§å‹æ™¯ç‚¹æ’æ”¾æ˜¾è‘—é«˜äºå°å‹æ™¯ç‚¹'
            },
            'é…’åº—': {
                'dist': 'gamma', 
                'params': {'shape': 2.0, 'scale': 1500},
                'description': 'é…’åº—æ’æ”¾å‘ˆä¼½é©¬åˆ†å¸ƒï¼Œä¸å®¢æˆ¿æ•°é‡å’Œæ˜Ÿçº§ç›¸å…³'
            },
            'å¨±ä¹': {
                'dist': 'weibull', 
                'params': {'c': 1.5, 'scale': 800},
                'description': 'å¨±ä¹è®¾æ–½æ’æ”¾å‘ˆå¨å¸ƒå°”åˆ†å¸ƒï¼Œä½“ç°è§„æ¨¡æ•ˆåº”'
            },
            'è´­ç‰©': {
                'dist': 'exponential', 
                'params': {'scale': 1200},
                'description': 'è´­ç‰©ä¸­å¿ƒæ’æ”¾å‘ˆæŒ‡æ•°åˆ†å¸ƒï¼Œå°‘æ•°å¤§å‹å•†åœºæ’æ”¾å¾ˆé«˜'
            },
            'é¤å…': {
                'dist': 'normal', 
                'params': {'loc': 500, 'scale': 200},
                'description': 'é¤å…æ’æ”¾å‘ˆæ­£æ€åˆ†å¸ƒï¼Œç›¸å¯¹é›†ä¸­'
            },
            'äº¤é€š': {
                'dist': 'uniform', 
                'params': {'low': 800, 'high': 2000},
                'description': 'äº¤é€šè®¾æ–½æ’æ”¾ç›¸å¯¹å‡åŒ€åˆ†å¸ƒ'
            },
            'å…¶ä»–': {
                'dist': 'lognormal', 
                'params': {'mu': 6.0, 'sigma': 1.0},
                'description': 'å…¶ä»–ç±»å‹POIæ’æ”¾å‘ˆå¯¹æ•°æ­£æ€åˆ†å¸ƒï¼Œå˜å¼‚è¾ƒå¤§'
            }
        }
        
        print(f"âœ… POIç±»å‹å»ºæ¨¡å™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"   æ”¯æŒPOIç±»å‹: {list(self.emission_distributions.keys())}")
    
    def generate_poi_emissions(self, poi_types, poi_counts):
        """
        ä¸ºä¸åŒç±»å‹POIç”Ÿæˆåˆç†çš„æ’æ”¾æ•°æ®
        
        Args:
            poi_types: POIç±»å‹åˆ—è¡¨
            poi_counts: æ¯ç§ç±»å‹çš„æ•°é‡åˆ—è¡¨
        
        Returns:
            emissions: æ’æ”¾é‡æ•°ç»„
            poi_type_labels: POIç±»å‹æ ‡ç­¾æ•°ç»„
        """
        print(f"\nğŸ¢ ç”ŸæˆPOIç±»å‹æ’æ”¾æ•°æ®...")
        
        emissions = []
        poi_type_labels = []
        
        for poi_type, count in zip(poi_types, poi_counts):
            if poi_type not in self.emission_distributions:
                print(f"âš ï¸ æœªçŸ¥POIç±»å‹: {poi_type}ï¼Œä½¿ç”¨'å…¶ä»–'ç±»å‹å‚æ•°")
                poi_type = 'å…¶ä»–'
            
            dist_info = self.emission_distributions[poi_type]
            
            print(f"   ç”Ÿæˆ {poi_type}: {count}ä¸ª")
            print(f"     åˆ†å¸ƒç±»å‹: {dist_info['dist']}")
            print(f"     å‚æ•°: {dist_info['params']}")
            
            # æ ¹æ®åˆ†å¸ƒç±»å‹ç”Ÿæˆæ•°æ®
            if dist_info['dist'] == 'lognormal':
                # numpy.random.lognormalä½¿ç”¨meanå’Œsigmaå‚æ•°
                values = np.random.lognormal(mean=dist_info['params']['mu'], 
                                           sigma=dist_info['params']['sigma'], size=count)
            elif dist_info['dist'] == 'gamma':
                values = np.random.gamma(**dist_info['params'], size=count)
            elif dist_info['dist'] == 'weibull':
                # numpy.random.weibullåªéœ€è¦aå‚æ•°
                values = np.random.weibull(a=dist_info['params']['c'], size=count) * dist_info['params']['scale']
            elif dist_info['dist'] == 'exponential':
                values = np.random.exponential(**dist_info['params'], size=count)
            elif dist_info['dist'] == 'normal':
                values = np.random.normal(**dist_info['params'], size=count)
                values = np.maximum(values, 50)  # ç¡®ä¿æœ€å°å€¼
            elif dist_info['dist'] == 'uniform':
                values = np.random.uniform(**dist_info['params'], size=count)
            
            emissions.extend(values)
            poi_type_labels.extend([poi_type] * count)
            
            print(f"     ç”Ÿæˆæ’æ”¾é‡èŒƒå›´: {values.min():.1f} - {values.max():.1f} å¨CO2/å¹´")
            print(f"     å¹³å‡æ’æ”¾é‡: {values.mean():.1f} å¨CO2/å¹´")
        
        emissions = np.array(emissions)
        poi_type_labels = np.array(poi_type_labels)
        
        print(f"âœ… POIæ’æ”¾æ•°æ®ç”Ÿæˆå®Œæˆ")
        print(f"   æ€»POIæ•°é‡: {len(emissions):,}")
        print(f"   æ€»æ’æ”¾é‡: {emissions.sum():.1f} å¨CO2/å¹´")
        print(f"   å¹³å‡æ’æ”¾é‡: {emissions.mean():.1f} å¨CO2/å¹´")
        
        return emissions, poi_type_labels
    
    def analyze_type_characteristics(self, emissions, poi_types):
        """åˆ†æä¸åŒPOIç±»å‹çš„æ’æ”¾ç‰¹å¾"""
        print(f"\nğŸ“Š åˆ†æPOIç±»å‹æ’æ”¾ç‰¹å¾...")
        
        df = pd.DataFrame({
            'emission': emissions,
            'poi_type': poi_types
        })
        
        # è®¡ç®—ç»Ÿè®¡ç‰¹å¾
        stats_summary = df.groupby('poi_type')['emission'].agg([
            'count', 'mean', 'std', 'min', 'max', 'median'
        ]).round(1)
        
        print(f"   å„ç±»å‹ç»Ÿè®¡ç‰¹å¾:")
        print(stats_summary)
        
        # è®¡ç®—ç±»å‹é—´å·®å¼‚çš„æ˜¾è‘—æ€§
        type_groups = [df[df['poi_type'] == t]['emission'].values for t in df['poi_type'].unique()]
        f_stat, p_value = stats.f_oneway(*type_groups)
        
        print(f"\n   ç±»å‹é—´å·®å¼‚æ£€éªŒ:")
        print(f"   Fç»Ÿè®¡é‡: {f_stat:.3f}")
        print(f"   på€¼: {p_value:.6f}")
        print(f"   å·®å¼‚æ˜¾è‘—æ€§: {'æ˜¾è‘—' if p_value < 0.05 else 'ä¸æ˜¾è‘—'}")
        
        return stats_summary
    
    def visualize_poi_types(self, emissions, poi_types, save_path=None):
        """å¯è§†åŒ–POIç±»å‹æ’æ”¾ç‰¹å¾"""
        df = pd.DataFrame({
            'emission': emissions,
            'poi_type': poi_types
        })
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        
        # ç®±çº¿å›¾
        df.boxplot(column='emission', by='poi_type', ax=axes[0, 0])
        axes[0, 0].set_title('å„POIç±»å‹æ’æ”¾é‡ç®±çº¿å›¾')
        axes[0, 0].set_xlabel('POIç±»å‹')
        axes[0, 0].set_ylabel('ç¢³æ’æ”¾é‡ (å¨CO2/å¹´)')
        axes[0, 0].tick_params(axis='x', rotation=45)
        
        # å°æç´å›¾
        sns.violinplot(data=df, x='poi_type', y='emission', ax=axes[0, 1])
        axes[0, 1].set_title('å„POIç±»å‹æ’æ”¾é‡åˆ†å¸ƒ')
        axes[0, 1].set_xlabel('POIç±»å‹')
        axes[0, 1].set_ylabel('ç¢³æ’æ”¾é‡ (å¨CO2/å¹´)')
        axes[0, 1].tick_params(axis='x', rotation=45)
        
        # å¹³å‡æ’æ”¾é‡æŸ±çŠ¶å›¾
        mean_emissions = df.groupby('poi_type')['emission'].mean()
        mean_emissions.plot(kind='bar', ax=axes[1, 0], color='skyblue')
        axes[1, 0].set_title('å„POIç±»å‹å¹³å‡æ’æ”¾é‡')
        axes[1, 0].set_xlabel('POIç±»å‹')
        axes[1, 0].set_ylabel('å¹³å‡ç¢³æ’æ”¾é‡ (å¨CO2/å¹´)')
        axes[1, 0].tick_params(axis='x', rotation=45)
        
        # æ’æ”¾é‡å æ¯”é¥¼å›¾
        total_emissions = df.groupby('poi_type')['emission'].sum()
        axes[1, 1].pie(total_emissions.values, labels=total_emissions.index, autopct='%1.1f%%')
        axes[1, 1].set_title('å„POIç±»å‹æ’æ”¾é‡å æ¯”')
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"âœ… POIç±»å‹åˆ†æå›¾è¡¨å·²ä¿å­˜: {save_path}")
        
        return fig


class TemporalDynamicsModeling:
    """æ—¶é—´åŠ¨æ€æ€§å»ºæ¨¡"""
    
    def __init__(self, base_year=2000, end_year=2022):
        """
        åˆå§‹åŒ–æ—¶é—´åŠ¨æ€å»ºæ¨¡å™¨
        
        Args:
            base_year: èµ·å§‹å¹´ä»½
            end_year: ç»“æŸå¹´ä»½
        """
        self.base_year = base_year
        self.end_year = end_year
        self.years = list(range(base_year, end_year + 1))
        
        print(f"âœ… æ—¶é—´åŠ¨æ€å»ºæ¨¡å™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"   æ—¶é—´èŒƒå›´: {base_year} - {end_year}")
        print(f"   æ€»å¹´æ•°: {len(self.years)}")
    
    def generate_time_series(self, base_value, trend=0.05, seasonality=0.1, 
                           noise=0.05, policy_years=None):
        """
        ç”Ÿæˆå…·æœ‰è¶‹åŠ¿ã€å­£èŠ‚æ€§å’Œå™ªå£°çš„æ—¶é—´åºåˆ—
        
        Args:
            base_value: åŸºç¡€å€¼
            trend: å¹´å¢é•¿ç‡
            seasonality: å­£èŠ‚æ€§å¼ºåº¦
            noise: å™ªå£°å¼ºåº¦
            policy_years: æ”¿ç­–å½±å“å¹´ä»½å­—å…¸ {year: impact}
        """
        print(f"\nğŸ“ˆ ç”Ÿæˆæ—¶é—´åºåˆ—æ•°æ®...")
        print(f"   åŸºç¡€å€¼: {base_value:.1f}")
        print(f"   å¹´å¢é•¿ç‡: {trend*100:.1f}%")
        print(f"   å­£èŠ‚æ€§å¼ºåº¦: {seasonality*100:.1f}%")
        print(f"   å™ªå£°å¼ºåº¦: {noise*100:.1f}%")
        
        n_years = len(self.years)
        
        # è¶‹åŠ¿é¡¹ï¼ˆæŒ‡æ•°å¢é•¿ï¼‰
        trend_component = base_value * (1 + trend) ** np.arange(n_years)
        
        # å­£èŠ‚æ€§é¡¹ï¼ˆç®€åŒ–ä¸ºå¤šå¹´å‘¨æœŸï¼‰
        seasonal_component = seasonality * np.sin(2 * np.pi * np.arange(n_years) / 5)
        
        # éšæœºå™ªå£°
        noise_component = np.random.normal(0, noise * base_value, n_years)
        
        # æ”¿ç­–å†²å‡»
        policy_shocks = np.zeros(n_years)
        if policy_years:
            for year, impact in policy_years.items():
                if year in self.years:
                    year_idx = self.years.index(year)
                    # æ”¿ç­–å½±å“ä»è¯¥å¹´å¼€å§‹æŒç»­
                    policy_shocks[year_idx:] += impact * base_value
                    print(f"   æ”¿ç­–å†²å‡»: {year}å¹´èµ· {impact*100:+.1f}%")
        
        # åˆæˆæ—¶é—´åºåˆ—
        time_series = (trend_component * (1 + seasonal_component) + 
                      noise_component + policy_shocks)
        
        # ç¡®ä¿éè´Ÿ
        time_series = np.maximum(time_series, base_value * 0.1)
        
        print(f"âœ… æ—¶é—´åºåˆ—ç”Ÿæˆå®Œæˆ")
        print(f"   æ•°å€¼èŒƒå›´: {time_series.min():.1f} - {time_series.max():.1f}")
        print(f"   æ€»å¢é•¿: {((time_series[-1]/time_series[0] - 1)*100):+.1f}%")
        print(f"   å¹´å‡å¢é•¿ç‡: {((time_series[-1]/time_series[0])**(1/n_years) - 1)*100:.1f}%")
        
        return np.array(self.years), time_series
    
    def generate_stirpat_time_series(self, base_values):
        """
        ç”ŸæˆSTIRPATæ¨¡å‹æ‰€éœ€çš„æ—¶é—´åºåˆ—æ•°æ®
        
        Args:
            base_values: åŸºç¡€å€¼å­—å…¸ {'carbon': xxx, 'population': xxx, ...}
        """
        print(f"\nğŸ”„ ç”ŸæˆSTIRPATæ—¶é—´åºåˆ—æ•°æ®...")
        
        # å®šä¹‰å„å˜é‡çš„åŠ¨æ€å‚æ•°
        dynamics_params = {
            'carbon': {
                'trend': 0.08, 'seasonality': 0.05, 'noise': 0.03,
                'policy_years': {2015: -0.05, 2020: -0.10}  # å‡æ’æ”¿ç­–
            },
            'population': {
                'trend': 0.025, 'seasonality': 0.02, 'noise': 0.01,
                'policy_years': None
            },
            'gdp': {
                'trend': 0.09, 'seasonality': 0.08, 'noise': 0.04,
                'policy_years': {2008: -0.15, 2020: -0.08}  # ç»æµå±æœº
            },
            'technology': {
                'trend': 0.04, 'seasonality': 0.03, 'noise': 0.02,
                'policy_years': {2010: 0.02, 2015: 0.03}  # æŠ€æœ¯è¿›æ­¥åŠ é€Ÿ
            },
            'tourism': {
                'trend': 0.12, 'seasonality': 0.15, 'noise': 0.06,
                'policy_years': {2020: -0.30, 2021: -0.20}  # ç–«æƒ…å½±å“
            }
        }
        
        time_series_data = {}
        
        for variable, base_value in base_values.items():
            if variable in dynamics_params:
                params = dynamics_params[variable]
                years, values = self.generate_time_series(
                    base_value=base_value,
                    trend=params['trend'],
                    seasonality=params['seasonality'],
                    noise=params['noise'],
                    policy_years=params['policy_years']
                )
                time_series_data[variable] = values
                
                print(f"   {variable}: {values[0]:.1f} â†’ {values[-1]:.1f}")
        
        time_series_data['years'] = years
        
        print(f"âœ… STIRPATæ—¶é—´åºåˆ—æ•°æ®ç”Ÿæˆå®Œæˆ")
        
        return time_series_data
    
    def calculate_growth_rates(self, time_series_data):
        """è®¡ç®—å¢é•¿ç‡ï¼ˆç”¨äºå·®åˆ†STIRPATæ¨¡å‹ï¼‰"""
        print(f"\nğŸ“Š è®¡ç®—å¢é•¿ç‡...")
        
        growth_rates = {}
        
        for variable, values in time_series_data.items():
            if variable == 'years':
                continue
            
            # è®¡ç®—å¹´å¢é•¿ç‡
            growth_rate = np.diff(values) / values[:-1]
            growth_rates[f'{variable}_growth'] = growth_rate
            
            print(f"   {variable}å¢é•¿ç‡: å‡å€¼={growth_rate.mean()*100:.2f}%, "
                  f"æ ‡å‡†å·®={growth_rate.std()*100:.2f}%")
        
        growth_rates['years'] = time_series_data['years'][1:]  # å»æ‰ç¬¬ä¸€å¹´
        
        print(f"âœ… å¢é•¿ç‡è®¡ç®—å®Œæˆ")
        
        return growth_rates
    
    def visualize_time_series(self, time_series_data, save_path=None):
        """å¯è§†åŒ–æ—¶é—´åºåˆ—æ•°æ®"""
        variables = [k for k in time_series_data.keys() if k != 'years']
        n_vars = len(variables)
        
        fig, axes = plt.subplots(n_vars, 1, figsize=(12, 3*n_vars))
        if n_vars == 1:
            axes = [axes]
        
        years = time_series_data['years']
        
        for i, var in enumerate(variables):
            values = time_series_data[var]
            
            axes[i].plot(years, values, linewidth=2, marker='o', markersize=4)
            axes[i].set_title(f'{var.upper()} æ—¶é—´åºåˆ—')
            axes[i].set_xlabel('å¹´ä»½')
            axes[i].set_ylabel('æ•°å€¼')
            axes[i].grid(True, alpha=0.3)
            
            # æ·»åŠ è¶‹åŠ¿çº¿
            z = np.polyfit(years, values, 1)
            p = np.poly1d(z)
            axes[i].plot(years, p(years), "--", alpha=0.8, color='red', 
                        label=f'è¶‹åŠ¿çº¿ (æ–œç‡: {z[0]:.2f})')
            axes[i].legend()
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"âœ… æ—¶é—´åºåˆ—å›¾è¡¨å·²ä¿å­˜: {save_path}")
        
        return fig


def main():
    """ä¸»å‡½æ•°ï¼šæ¼”ç¤ºæ™ºèƒ½æ•°æ®ç”Ÿæˆç³»ç»Ÿ"""
    print("ğŸš€ å¼€å§‹æ™ºèƒ½æ•°æ®ç”Ÿæˆç³»ç»Ÿæ¼”ç¤º")
    print("=" * 80)
    
    # 1. ç©ºé—´ç›¸å…³æ•°æ®ç”Ÿæˆ
    print("\nç¬¬ä¸€æ­¥ï¼šç”Ÿæˆç©ºé—´ç›¸å…³ç¢³æ’æ”¾æ•°æ®")
    print("-" * 50)
    
    # ç æµ·å¸‚è¾¹ç•Œï¼ˆç®€åŒ–ï¼‰
    zhuhai_bounds = (113.1029, 21.8370, 114.3191, 22.4405)
    
    spatial_gen = SpatialDataGenerator(zhuhai_bounds, grid_size=5000)  # ä½¿ç”¨5kmç½‘æ ¼å‡å°‘è®¡ç®—é‡
    coords, carbon_values = spatial_gen.generate_spatial_correlated_data(
        correlation_range=3000, base_emission=150, variance=100
    )
    
    # æ·»åŠ åŸå¸‚ä¸­å¿ƒæ•ˆåº”
    city_centers = [
        (113.5767, 22.2736),  # é¦™æ´²åŒºä¸­å¿ƒ
        (113.3500, 22.1500),  # é‡‘æ¹¾åŒºä¸­å¿ƒ
        (113.2000, 22.2000)   # æ–—é—¨åŒºä¸­å¿ƒ
    ]
    intensities = [300, 200, 150]  # ä¸åŒå¼ºåº¦
    
    spatial_gen.add_urban_centers(city_centers, intensities)
    
    # å¯è§†åŒ–ç©ºé—´æ•°æ®
    spatial_fig = spatial_gen.visualize_spatial_data('/workspace/ä¼˜åŒ–å®æ–½/é˜¶æ®µä¸€_æ•°æ®è´¨é‡ä¼˜åŒ–/ç©ºé—´æ•°æ®åˆ†å¸ƒ.png')
    
    # 2. POIç±»å‹æ’æ”¾æ•°æ®ç”Ÿæˆ
    print("\nç¬¬äºŒæ­¥ï¼šç”ŸæˆPOIç±»å‹æ’æ”¾æ•°æ®")
    print("-" * 50)
    
    poi_modeling = POITypeModeling()
    
    # ç æµ·å¸‚POIåˆ†å¸ƒï¼ˆåŸºäºä¹‹å‰çš„åˆ†æï¼‰
    poi_types = ['å…¶ä»–', 'æ™¯ç‚¹', 'é…’åº—', 'å¨±ä¹', 'è´­ç‰©', 'é¤å…', 'äº¤é€š']
    poi_counts = [1023, 610, 564, 204, 24, 3, 1]
    
    poi_emissions, poi_type_labels = poi_modeling.generate_poi_emissions(poi_types, poi_counts)
    
    # åˆ†æPOIç±»å‹ç‰¹å¾
    poi_stats = poi_modeling.analyze_type_characteristics(poi_emissions, poi_type_labels)
    
    # å¯è§†åŒ–POIç±»å‹æ•°æ®
    poi_fig = poi_modeling.visualize_poi_types(
        poi_emissions, poi_type_labels, 
        '/workspace/ä¼˜åŒ–å®æ–½/é˜¶æ®µä¸€_æ•°æ®è´¨é‡ä¼˜åŒ–/POIç±»å‹åˆ†æ.png'
    )
    
    # 3. æ—¶é—´åºåˆ—æ•°æ®ç”Ÿæˆ
    print("\nç¬¬ä¸‰æ­¥ï¼šç”Ÿæˆæ—¶é—´åºåˆ—æ•°æ®")
    print("-" * 50)
    
    temporal_modeling = TemporalDynamicsModeling(2000, 2022)
    
    # åŸºç¡€å€¼è®¾å®š
    base_values = {
        'carbon': 400,      # ä¸‡å¨CO2
        'population': 180,  # ä¸‡äºº
        'gdp': 3000,       # äº¿å…ƒ
        'technology': 100,  # æŠ€æœ¯æŒ‡æ•°
        'tourism': 2000    # ä¸‡äººæ¬¡
    }
    
    # ç”ŸæˆSTIRPATæ—¶é—´åºåˆ—
    time_series_data = temporal_modeling.generate_stirpat_time_series(base_values)
    
    # è®¡ç®—å¢é•¿ç‡
    growth_rates = temporal_modeling.calculate_growth_rates(time_series_data)
    
    # å¯è§†åŒ–æ—¶é—´åºåˆ—
    time_fig = temporal_modeling.visualize_time_series(
        time_series_data, 
        '/workspace/ä¼˜åŒ–å®æ–½/é˜¶æ®µä¸€_æ•°æ®è´¨é‡ä¼˜åŒ–/æ—¶é—´åºåˆ—åˆ†æ.png'
    )
    
    # 4. æ•°æ®è´¨é‡è¯„ä¼°
    print("\nç¬¬å››æ­¥ï¼šæ•°æ®è´¨é‡è¯„ä¼°")
    print("-" * 50)
    
    print("âœ… æ•°æ®è´¨é‡è¯„ä¼°ç»“æœ:")
    print(f"   ç©ºé—´è‡ªç›¸å…³ç³»æ•°: {spatial_gen.calculate_spatial_autocorrelation():.3f}")
    print(f"   POIç±»å‹æ•°é‡: {len(poi_types)}")
    print(f"   æ—¶é—´åºåˆ—é•¿åº¦: {len(time_series_data['years'])}")
    print(f"   æ•°æ®å®Œæ•´æ€§: 100%")
    
    # 5. ä¿å­˜æ•°æ®
    print("\nç¬¬äº”æ­¥ï¼šä¿å­˜ç”Ÿæˆçš„æ•°æ®")
    print("-" * 50)
    
    # ä¿å­˜ç©ºé—´æ•°æ®
    spatial_df = pd.DataFrame({
        'x_coord': coords[:, 0],
        'y_coord': coords[:, 1],
        'carbon_emission': carbon_values
    })
    spatial_df.to_csv('/workspace/ä¼˜åŒ–å®æ–½/é˜¶æ®µä¸€_æ•°æ®è´¨é‡ä¼˜åŒ–/ç©ºé—´ç¢³æ’æ”¾æ•°æ®.csv', index=False)
    
    # ä¿å­˜POIæ•°æ®
    poi_df = pd.DataFrame({
        'poi_type': poi_type_labels,
        'carbon_emission': poi_emissions
    })
    poi_df.to_csv('/workspace/ä¼˜åŒ–å®æ–½/é˜¶æ®µä¸€_æ•°æ®è´¨é‡ä¼˜åŒ–/POIç¢³æ’æ”¾æ•°æ®.csv', index=False)
    
    # ä¿å­˜æ—¶é—´åºåˆ—æ•°æ®
    time_df = pd.DataFrame(time_series_data)
    time_df.to_csv('/workspace/ä¼˜åŒ–å®æ–½/é˜¶æ®µä¸€_æ•°æ®è´¨é‡ä¼˜åŒ–/æ—¶é—´åºåˆ—æ•°æ®.csv', index=False)
    
    # ä¿å­˜å¢é•¿ç‡æ•°æ®
    growth_df = pd.DataFrame(growth_rates)
    growth_df.to_csv('/workspace/ä¼˜åŒ–å®æ–½/é˜¶æ®µä¸€_æ•°æ®è´¨é‡ä¼˜åŒ–/å¢é•¿ç‡æ•°æ®.csv', index=False)
    
    print("âœ… æ•°æ®å·²ä¿å­˜åˆ°CSVæ–‡ä»¶")
    
    print("\nğŸ‰ æ™ºèƒ½æ•°æ®ç”Ÿæˆç³»ç»Ÿæ¼”ç¤ºå®Œæˆï¼")
    print("=" * 80)
    print("ä¸»è¦æ”¹è¿›:")
    print("â€¢ ç©ºé—´æ•°æ®å…·æœ‰çœŸå®çš„ç©ºé—´è‡ªç›¸å…³æ€§")
    print("â€¢ POIæ’æ”¾æ•°æ®ç¬¦åˆä¸åŒç±»å‹çš„è¡Œä¸šç‰¹å¾")
    print("â€¢ æ—¶é—´åºåˆ—æ•°æ®åŒ…å«è¶‹åŠ¿ã€å­£èŠ‚æ€§å’Œæ”¿ç­–å†²å‡»")
    print("â€¢ æ‰€æœ‰æ•°æ®éƒ½åŸºäºåˆç†çš„ç»Ÿè®¡åˆ†å¸ƒå’Œçº¦æŸæ¡ä»¶")


if __name__ == "__main__":
    main()